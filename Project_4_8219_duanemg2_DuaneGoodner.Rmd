---
title: 'Project 4: Movie Recommendation'
author: "Fall 2021, Duane Goodner (netID = duanemg2)"
date: "12/12/2021"
output:
  html_document:
    theme: readable
    toc: yes
    toc_float: yes
    code_download: true
---

# 1. Introduction

This document contains the description and implementation of genre (query-based)  and collaborative filtering systems for recommending movies to users based on their reported genre preference and/or a sample of rated movies. The dataset for this project consists of approximately 1 million ratings of 3900 movies by 6040 MovieLens users. A companion web-based shiny app using these algorithms with the same dataset is at: https://duanegoodner.shinyapps.io/movie_shiny_app/.

# 2. Genre Based Recommender Systems

## 2.1 Loading Packages and Data

First, we make sure the necessary packages are loaded.
```{r, message=FALSE}
ensure_packages <- function(package_names) {
  tmp <- setdiff(package_names, rownames(installed.packages()))
  if (length(tmp) > 0) install.packages(tmp)
  lapply(package_names, require, character.only = TRUE)
}

invisible(ensure_packages(c("dplyr", "caret", "recommenderlab", "data.table", "DT")))
```


We then add a function that will be used to import Movie, Rating and User data into the environment where will will run the genre-based recommendation algorithms. The body of this function was provided in the course material at: https://liangfgithub.github.io/Rcode_W13_Movie_EDA.nb.html

```{r}
import_data <- function(proj_env) {
  with(proj_env, {
    data_url <- "https://liangfgithub.github.io/MovieData/"
    
    # import ratings data
    # use colClasses = 'NULL' to skip columns
    ratings <- read.csv(paste0(data_url, 'ratings.dat?raw=true'), 
                        sep = ':',
                        colClasses = c('integer', 'NULL'), 
                        header = FALSE)
    colnames(ratings) <- c('UserID', 'MovieID', 'Rating', 'Timestamp')
    
    
    # import movies data
    movies <- readLines(paste0(data_url, 'movies.dat?raw=true'))
    movies <- strsplit(movies, split = "::", fixed = TRUE, useBytes = TRUE)
    movies <- matrix(unlist(movies), ncol = 3, byrow = TRUE)
    movies <- data.frame(movies, stringsAsFactors = FALSE)
    colnames(movies) <- c('MovieID', 'Title', 'Genres')
    movies$MovieID <- as.integer(movies$MovieID)
    
    # convert accented characters
    movies$Title[73]
    movies$Title <- iconv(movies$Title, "latin1", "UTF-8")
    movies$Title[73]
    
    # extract year
    movies$Year <- as.numeric(unlist(
      lapply(movies$Title, function(x) substr(x, nchar(x) - 4, nchar(x) - 1))))
    
    
    # import user data
    users <- read.csv(paste0(data_url, 'users.dat?raw=true'),
                      sep = ':', header = FALSE)
    users <- users[, -c(2,4,6,8)] # skip columns
    colnames(users) <- c('UserID', 'Gender', 'Age', 'Occupation', 'Zip-code')
  })
}
```

We then create an environment (named `system_01` that will contain objects for the genre-based recommender algorithms and import raw data into this environment.

```{r}
system_01 <- new.env()
import_data(system_01)
```


## 2.2 Building a Genre Matrix  

Next, we define function `build_genre_matrix` that will create a dataframe with a row for each movie and a column for each genre. If a movie belongs to a particular genre, the entry for that movie-genre pair will be 1. Otherwise, the entry will be 0. After defining `build_genre_matrix`, we set `system_01` as its calling environment.
```{r}
build_genre_matrix <- function() {
  genres_str_list <- movies$Genres %>%
    lapply(strsplit, split = "[|]") %>%
    unlist(recursive = FALSE)
  
  genre_names <- unlist(genres_str_list) %>%
    unique()
  
  genre_mat <- lapply(genres_str_list, \(x) {
    x %>%
      factor(levels = genre_names) %>%
      class2ind() %>% colSums
  }) %>%
    bind_rows()
  
  system_01$genre_matrix <- data.frame(MovieID = movies$MovieID,
                                          genre_mat, check.names = FALSE)
}

environment(build_genre_matrix) <- system_01
```

We then run function `build_genre_matrix` so we have a genre matrix available for use in the `system_01` environment.
```{r}
build_genre_matrix()
```


## 2.3 Query Functions

Next, we build two different query function that will each recommend 5 (different) movies based on the knowledge of a user's favorite genre. 

## 2.3.1 Highest rated among 25% most "popular" (frequently rated) movies in genre

The first of these functions restricts its search to 25% of movies in the genre with the most ratings. It returns the 5 highest rated among the upper quartile of most-rated movies from the genre. As was the case with `buid_genre_matrix()`, we also set `system_01` as the calling environment.
```{r}
top_rated_popular_of_genre <- function(genre, num_movies = 5) {
  df <- genre_matrix[
    which(genre_matrix[[genre]] == 1), ] %>%
    inner_join(ratings, by = 'MovieID') %>%
    group_by(MovieID) %>%
    summarize(ratings_per_movie = n(), ave_rating = mean(Rating)) %>%
    inner_join(movies, by = 'MovieID')
  
  num_ratings_cutoff <- summary(df$ratings_per_movie)["3rd Qu."]
  
  df <- df[which(df$ratings_per_movie > num_ratings_cutoff), ] %>%
    arrange(desc(ave_rating)) %>%
    head(num_movies)
  
  return(df[, c('Title', 'Genres', 'Year', 'ratings_per_movie', 'ave_rating', 'MovieID')])
}
environment(top_rated_popular_of_genre) <- system_01
```


### 2.3.2 Reasonably popular and highly movies that are combined with highest number of additional genres

For our second genre-based recommendation algorithm we write function that restricts its search to movies that belong to the genre of interest and are in the upper 50% of both average ratings and number of ratings received. It returns movies from this set that belong to the most additional genres. A motivation for this type of algorithm is to encourage users to "branch out" into other genres.

```{r}
most_other_genres_high_rate_popular <- function(genre, num_movies = 5) {
  genre_names <- names(genre_matrix)[which(names(genre_matrix) != "MovieID")]
  
  df <- genre_matrix[
    which(genre_matrix[[genre]] == 1), ] %>%
    inner_join(ratings, by = 'MovieID') %>%
    group_by(MovieID) %>%
    summarize(ratings_per_movie = n(), ave_rating = mean(Rating)) %>%
    inner_join(movies, by = 'MovieID')
  
  num_ratings_cutoff <- median(df$ratings_per_movie)
  ave_rating_cutoff <- median(df$ave_rating)
  
  df <- df[which(df$ratings_per_movie > num_ratings_cutoff &
                   df$ave_rating > ave_rating_cutoff), ] %>%
    left_join(genre_matrix, by = 'MovieID')
  
  df <- arrange(df, desc(rowSums(df[, genre_names]))) %>%
    head(num_movies)
    
  
  return(df[, c('Title', 'Genres', 'Year', 'ratings_per_movie', 'ave_rating', 'MovieID')])
}
environment(most_other_genres_high_rate_popular) <- system_01
```


## 2.4 Genre based recommender results

For each of the two query functions, we use `lapply` to obtain results for each of the 18 genres.
```{r}
with(system_01, {
  top_rated_popular <- colnames(genre_matrix[-1]) %>%
    lapply(top_rated_popular_of_genre) %>%
    setNames(colnames(genre_matrix[-1]))
  
  most_other_genres_top_rated_popular <- colnames(genre_matrix[-1]) %>%
    lapply(most_other_genres_high_rate_popular) %>%
    setNames(colnames(genre_matrix[-1]))
  
})
```
Variables `top_rated_popular` and `most_other_genres_top_rated_popular` are both 18-member lists, with each list entry consisting of a tibble of recommended movies. Two of these tibbles is shown here. The complete lists with all (36) tibbles are included in the Appendix.

```{r}
datatable(system_01$top_rated_popular$Action, class = "nowrap hover row-border", 
            escape = FALSE, 
            options = list(dom = 't',
                           scrollX = TRUE, autoWidth = TRUE))
```

```{r}
datatable(system_01$most_other_genres_top_rated_popular$Comedy,
          class = "nowrap hover row-border", 
            escape = FALSE, 
            options = list(dom = 't',
                           scrollX = TRUE, autoWidth = TRUE))

```

# 3. Collaboarative Filtering Recommenders

## 3.1 Algorithm Descriptions

### 3.1.2 SVD (with Column Means Imputation)

The first predictor method evaluated (and the one used in the Shiny App) was Singular Value Decomposition with Column Means imputation. For this algorithm, the only tuning parameter is `k`, the number of SVD components used. **We use k = 50 components**.

The objective function for column means imputation SVD is:
$$\underset{A \in R^{n x M}, B \in R^{p x M}}{\mathrm{argmin}} \sum_{(i,j)\in O}(x_{ij} - \sum_{m=1}^M a_{im} b_{jm})^2$$
where *O* is the set of all observed pairs of indices, $a_{im}$ are elements in the matrix of component score vectors, and $b_{jm}$ are elements in a matrix whose columns are eigenvectors. This objective function is difficult/impossible to solve exactly, but we can find a numeric approximation by starting with column means as estimates of the missing values, finding principal components of the column means estimated version of $x_{ij}$, using these components to recompute the missing values, and repeating until the objective function no longer decreases. 


<br> 

### 3.1.3 UBCF

The second predictor algorithm evaluated was User Based Collaborative Filtering (UBCF). In this algorithm, we estimate missing rating values for a user by taking an average of the ratings for a movie provided by similar users. In our case, similarity between users was determined using **cosine similarity** given by:

$$\frac{u^{t}}{||u||\cdot||v||}$$
where *u* and *v* are ratings vectors of two users. The estimate of an unknown rating value is made using a weighted average of the known ratings value for the same movie provided by a neighborhood of similar users (who did provide a rating for the movie). 

For the UBCF predictor in our analysis, we use a **center-normalized ratings matrix** with a **cosine similarity metric** and a **neighborhood size of 50** (all defaults for `predictorlab` UBCF). We use a **weighted rating calculation** so that the weight of the prediction contribution for each user in the neighborhood is proportional to the value of the similarity metric between the test user and the neighbor observation (this is also a UBCF default).


## 3.2 Comparing Algorithms with Recommenderlab

First, we make sure the necessary packages are installed.
```{r, message=FALSE}
invisible(ensure_packages(c("recommenderlab", "Matrix")))
```

Next, we borrow a code snippet from the assignment instructions and use it to write a function for load ratings data into an environment.
```{r}
load_ratings <- function(data_env) {
  with(data_env, {
    data_url = "https://liangfgithub.github.io/MovieData/"
    ratings = read.csv(paste0(data_url, 'ratings.dat?raw=true'), 
                       sep = ':',
                       colClasses = c('integer', 'NULL'), 
                       header = FALSE)
    colnames(ratings) = c('UserID', 'MovieID', 'Rating', 'Timestamp')
    ratings$Timestamp = NULL
  })
}
```

We then create a new environment for the CF recommender systems and load the ratings data there.
```{r}
system_02 <- new.env()
load_ratings(system_02)
```

Next, we write functions for building a `Recommenderlab` "realRatingMatrix" and testing a list of algorithms. Note that `system_02` is set as the calling environment for each of these functions.

```{r}
build_rrm <- function(ratings_data) {
  user_ids <- as.factor(ratings_data$UserID)
  movie_ids <- as.factor(ratings_data$MovieID)
  r_sparse <- sparseMatrix(i = as.integer(user_ids),
                           j = as.integer(movie_ids),
                           x = ratings_data$Rating)
  rownames(r_sparse) <- paste0('u', as.character(levels(user_ids)))
  colnames(r_sparse) <- paste0('m', as.character(levels(movie_ids)))
  
  r_rrm <- as(r_sparse, "realRatingMatrix")
  
  return(r_rrm)
}
environment(build_rrm) <- system_02



test_algos <- function(eval_scheme, algo_list) {

  results <- evaluate(eval_scheme, algo_list, type = "ratings")
  errors <- lapply(results, getConfusionMatrix)

  return(data.frame(unlist(errors, recursive = FALSE)))
}
environment(test_algos) <- system_02
```

We also write a function that will be used to plot our results.
```{r}
rmse_box_plot <- function(eval_results) {
  results_df <- bind_rows(eval_results)
  boxplot(results_df[c("SVD.RMSE", "UBCF.RMSE")],
          ylab = "RMSE",
          main = "RMSE for SVD and UBCF Predictors (10 iterations each)")
}
environment(rmse_box_plot) <- system_02
```

With all our helper functions ready, we run the following code to build a ratings matrix, and run 10 iterations of a test-train split and RMSE comparison for SVD and UBCF predictors. Each iteration uses a separate test-train split, and the train fraction for each split is 0.9.
<br>

```{r}
set.seed(8219)

with(system_02, {
  r_rrm <- build_rrm(ratings)
  algos <- list(
    "SVD" = list(name="SVD", param=list(k = 50)),
    "UBCF" = list(name="UBCF", param=list(nn = 50))
  )
  
  eval_schemes <- vector(mode = "list", length = 10)
  
  for (scheme_num in 1:length(eval_schemes)) {
    eval_schemes[[scheme_num]] <- evaluationScheme(r_rrm, method = "split",
                                                   train = 0.9, given = 10)
  }
  
  eval_results <- lapply(eval_schemes, test_algos, algo_list = algos)
  
})
```

Finally, we plot our results comparing the test RMSEs of the two algorithms.
```{r}
with(system_02, {
  rmse_box_plot(eval_results)
})
```

Using the particular tuning parameters selected for the SVD and UBCF algorithms, SVD performs marginally better. It is important to keep in mind that no tuning was done for either model, so we cannot make any conclusions regarding the relative effectiveness of these approaches for our dataset.

# 4. References
- Shiny App code based on: https://github.com/pspachtholz/BookRecommender

- Recommender lab methods based on: https://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf

- Query algorithms based on examples at: https://liangfgithub.github.io/Rcode_W13_Movie_EDA.nb.html


# 5. Appendix: Movies retrieved by both genre-based queries for all 18 genres


```{r}
system_01$top_rated_popular
```


```{r}
system_01$most_other_genres_top_rated_popular
```






